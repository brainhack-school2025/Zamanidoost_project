{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deadf8f5-e227-458c-bedd-7a449ce9937b",
   "metadata": {},
   "source": [
    "## Step 4: Anchor Box Generation\n",
    "\n",
    "In this step, anchors are generated across the image using a fixed stride and a set of predefined shapes. Each anchor is represented in VOC format (xmin, ymin, xmax, ymax), and the total anchor set will be later used to match with ground truth boxes during training.\n",
    "\n",
    "- Anchors are centered every 8 pixels across a 512×512 grid.\n",
    "- Six different square anchor sizes are defined (e.g., 8×8 to 120×120).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a7b575-112a-4dc7-bd14-74d88e291493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "def to_VOC_format(width, height, center_x, center_y):\n",
    "    \"\"\"\n",
    "    Convert center coordinates format to VOC format (min-max coordinates)\n",
    "    \n",
    "    Parameters:\n",
    "    - width (float): The width of the bounding box\n",
    "    - height (float): The height of the bounding box\n",
    "    - center_x (float): The x-coordinate of the center of the bounding box\n",
    "    - center_y (float): The y-coordinate of the center of the bounding box\n",
    "    \n",
    "    Returns:\n",
    "    - x_min (float): The minimum x-coordinate of the bounding box\n",
    "    - y_min (float): The minimum y-coordinate of the bounding box\n",
    "    - x_max (float): The maximum x-coordinate of the bounding box\n",
    "    - y_max (float): The maximum y-coordinate of the bounding box\n",
    "    \"\"\"\n",
    "    x_min = center_x - 0.5 * width\n",
    "    y_min = center_y - 0.5 * height\n",
    "    x_max = center_x + 0.5 * width\n",
    "    y_max = center_y + 0.5 * height\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "def GIOU(box1, box2):\n",
    "    \"\"\"\n",
    "    Compute the Generalized Intersection over Union (GIOU) between box1 and box2.\n",
    "    This function measures the overlap between two bounding boxes and adjusts the IOU\n",
    "    by considering the smallest enclosing box that contains both.\n",
    "    \"\"\"\n",
    "    # Calculate coordinates of the overlapping region\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    if (x1 < x2 and y1 < y2):  # Check if there's any overlap\n",
    "        width_overlap = (x2 - x1)\n",
    "        height_overlap = (y2 - y1)\n",
    "        area_overlap = width_overlap * height_overlap\n",
    "    else:\n",
    "        iou = 0\n",
    "        area_overlap = 0\n",
    "\n",
    "    # Calculate the area of both boxes and their union\n",
    "    width_box1 = (box1[2] - box1[0])\n",
    "    height_box1 = (box1[3] - box1[1])\n",
    "    width_box2 = (box2[2] - box2[0])\n",
    "    height_box2 = (box2[3] - box2[1])\n",
    "    area_box1 = width_box1 * height_box1\n",
    "    area_box2 = width_box2 * height_box2\n",
    "    area_union = area_box1 + area_box2 - area_overlap\n",
    "\n",
    "    # Compute IOU\n",
    "    iou = area_overlap / area_union\n",
    "\n",
    "    # Calculate coordinates of the smallest enclosing box\n",
    "    x1 = min(box1[0], box2[0])\n",
    "    y1 = min(box1[1], box2[1])\n",
    "    x2 = max(box1[2], box2[2])\n",
    "    y2 = max(box1[3], box2[3])\n",
    "    enclosing_box_area = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "    # Compute GIOU\n",
    "    giou = iou - (enclosing_box_area - area_union) / enclosing_box_area\n",
    "\n",
    "    return giou\n",
    "####################################################################################3\n",
    "\n",
    "def to_center_format(xmin_list, ymin_list, xmax_list, ymax_list):\n",
    "    \"\"\"\n",
    "    Convert bounding box coordinates from (xmin, ymin, xmax, ymax) format to\n",
    "    (x_center, y_center, width, height) format.\n",
    "    \"\"\"\n",
    "    height = ymax_list - ymin_list\n",
    "    width = xmax_list - xmin_list\n",
    "    \n",
    "    center_x = xmin_list + 0.5 * width\n",
    "    center_y = ymin_list + 0.5 * height\n",
    "    \n",
    "    return width, height, center_x, center_y\n",
    "\n",
    "###################################################################################\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "stride = 8\n",
    "\n",
    "\n",
    "# Calculate anchor centers at every stride interval\n",
    "x_center = np.arange(3, 512, stride) # X-coordinates for anchor centers\n",
    "y_center = np.arange(3, 512, stride) # Y-coordinates for anchor centers\n",
    "        \n",
    "# Generate all ordered pairs of x and y centers\n",
    "center_list = np.array(np.meshgrid(x_center, y_center,  sparse=False, indexing='xy')).T.reshape(-1,2)\n",
    "    ##########################################################    \n",
    "# Define anchor box sizes (width, height)       \n",
    "anchor_shape = [(8,8),(25,25),(38,38),(58,58),(85,85),(120,120)]\n",
    "n_anchors = len(center_list) * len(anchor_shape) # Total number of anchors\n",
    "        \n",
    "# Initialize an array to store anchor boxes\n",
    "anchor_list = np.zeros(shape= (n_anchors, 4))\n",
    "\n",
    "# Generate anchor boxes for each center and each anchor size      \n",
    "count = 0\n",
    "for center in center_list:\n",
    "         center_x, center_y = center[0], center[1]\n",
    "         # Create anchors for each shape\n",
    "         for w,h in anchor_shape:\n",
    "             anchor_xmin,anchor_ymin,anchor_xmax,anchor_ymax = to_VOC_format(w, h, center_x, center_y)\n",
    "             # Store the anchor coordinates\n",
    "             anchor_list[count] = [anchor_xmin, anchor_ymin, anchor_xmax, anchor_ymax]\n",
    "             count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e0851-ce61-4f53-adf4-c47e2cc92abb",
   "metadata": {},
   "source": [
    "## Step 5: Data Loading and Preprocessing\n",
    "\n",
    "This step prepares image slices and corresponding tumor bounding boxes.\n",
    "\n",
    "- MRI data is loaded from a NIfTI file.\n",
    "- Bounding boxes are extracted from an Excel file and converted into arrays.\n",
    "- Each tumor’s position, size, and slice index are stored in a structured array for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54f71d7-dbcf-49ef-be5e-a1ad5ae6fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# === Load NIfTI MRI image ===\n",
    "nifti_path = './BrainHack/final_project/BraTS2021_00002_test.nii.gz'\n",
    "img = nib.load(nifti_path)\n",
    "img_data = img.get_fdata()\n",
    "\n",
    "# === Load bounding box info from Excel ===\n",
    "df = pd.read_excel('./Brainhack/final_project/bounding_boxes_test.xlsx')  # columns: slice, x, y, width, height\n",
    "\n",
    "'''\n",
    "# === Load NIfTI MRI image ===\n",
    "nifti_path = './BrainHack/final_project/BraTS2021_00002_train.nii.gz'\n",
    "img = nib.load(nifti_path)\n",
    "img_data = img.get_fdata()\n",
    "\n",
    "# === Load bounding box info from Excel ===\n",
    "df = pd.read_excel('./Brainhack/final_project/bounding_boxes_train.xlsx')  # columns: slice, x, y, width, height\n",
    "'''\n",
    "\n",
    "# Initialize an array to store relevant information from the dataset\n",
    "\n",
    "u = np.zeros((len(df), 5))\n",
    "u[:,0] = 0\n",
    "u[:,1] = 0\n",
    "u[:,2] = df['dia']\n",
    "u[:,3] = df['y-pos']\n",
    "u[:,4] = df['x-pos']\n",
    "\n",
    "################################################\n",
    "num_image = 100  # Number of images to process  #\n",
    "################################################\n",
    "row1 = list(df.iterrows())\n",
    "for i in range(num_image):\n",
    "    row = row1[i][1]\n",
    "    slice_index = int(row['filename'].replace('.png', ''))\n",
    "    u[i,1] = slice_index\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468a4e3-4532-4d38-bf10-1a7853f02c96",
   "metadata": {},
   "source": [
    "## Step 6: RPN Input Generation and Label Assignment\n",
    "\n",
    "This step prepares the input data for training a Region Proposal Network (RPN):\n",
    "\n",
    "- **Anchor matching:** For each ground truth box, anchor boxes are filtered (inside image bounds), and Generalized IoU (GIoU) is computed.\n",
    "- **Labeling:** Anchors are labeled as positive, negative, or ignored based on IoU thresholds.\n",
    "- **Regression targets:** Offsets (dx, dy, dw, dh) are calculated between anchors and their matching ground truth.\n",
    "- **Packaging:** Final data arrays (images, labels, offsets, GT boxes) are saved into a `.pkl` file for training and testing.\n",
    "\n",
    "> Output: `data_test.pkl` or `data_train.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eecc195a-5ae2-4dbd-969d-fdfc5e42d933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "(100, 512, 512, 3)\n",
      "(100, 24576, 5)\n",
      "(100, 24576, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ww = 512  # Image width and height \n",
    "\n",
    "\n",
    "nn_anch = np.int32((ww / stride) ** 2 * 6)  # Number of anchors per image\n",
    "\n",
    "# Initialize arrays for storing image data, offsets, labels, and bounding boxes\n",
    "image_data = np.zeros((num_image, 512, 512, 3))\n",
    "offset_list_label_list1 = np.zeros((num_image, nn_anch, 5))\n",
    "label_list1 = np.zeros((num_image, nn_anch, 1))\n",
    "bbox_list1 = np.zeros((num_image, 4))\n",
    "\n",
    "# Loop through each image to create input data and target labels for RPN training\n",
    "kk = 0\n",
    "for i in range(num_image):\n",
    "    index = int(u[i,1])\n",
    "\n",
    "    # Combine the three slices into one RGB image\n",
    "    img = np.zeros((512, 512, 3))\n",
    "    img[:, :, 0] = img_data[:,:,index-1]\n",
    "    img[:, :, 1] = img_data[:,:,index-1]\n",
    "    img[:, :, 2] = img_data[:,:,index-1]\n",
    "    \n",
    "    image_data[kk, :, :, :] = img\n",
    "    \n",
    "    # Convert the ground truth bounding box coordinates from center format to VOC format\n",
    "    x_min, y_min, x_max, y_max = to_VOC_format(u[i, 2], u[i, 2], u[i, 3], u[i, 4])\n",
    "    bbox_list = np.int32(np.array([x_min, y_min, x_max, y_max]))\n",
    "\n",
    "    \n",
    "    # Adjust the bounding box dimensions based on the resizing factor\n",
    "    \n",
    "    bbox_list = bbox_list \n",
    "    bbox_list1[kk, :] = bbox_list\n",
    "    n_object = len([bbox_list])\n",
    "\n",
    "    # Select anchor boxes that are within the image bounds\n",
    "    inside_anchor_idx_list = np.where(\n",
    "        (anchor_list[:, 0] >= 0) &\n",
    "        (anchor_list[:, 1] >= 0) &\n",
    "        (anchor_list[:, 2] <= ww) &\n",
    "        (anchor_list[:, 3] <= ww)\n",
    "    )[0]\n",
    "    \n",
    "    inside_anchor_list = anchor_list[inside_anchor_idx_list]\n",
    "    n_inside_anchor = len(inside_anchor_idx_list)\n",
    "    \n",
    "    # Calculate the GIOU between the ground truth boxes and the selected anchor boxes\n",
    "    iou_list = np.zeros((n_inside_anchor, n_object))\n",
    "    for gt_idx, gt_box in enumerate([bbox_list]):\n",
    "        for anchor_idx, anchor_box in enumerate(inside_anchor_list):\n",
    "            iou_list[anchor_idx] = GIOU(gt_box, anchor_box)  # Using GIOU instead of regular IOU\n",
    "    \n",
    "    # Assign labels to the anchors based on IoU values\n",
    "    data = {\"anchor_id\": inside_anchor_idx_list}\n",
    "    data.update({f\"object_{idx}_iou\": iou_list[:, idx] for idx in range(n_object)})\n",
    "    data[\"max_iou\"] = iou_list.max(axis=1)\n",
    "    data[\"best_gt\"] = iou_list.argmax(axis=1)\n",
    "    \n",
    "    df_iou = pd.DataFrame(data)\n",
    "    \n",
    "    # Identify the anchors with the highest IoU for each ground truth box\n",
    "    best_ious = df_iou.drop([\"anchor_id\", \"max_iou\", \"best_gt\"], axis=1).max().values\n",
    "    best_anchors = df_iou.drop([\"anchor_id\", \"max_iou\", \"best_gt\"], axis=1).values.argmax(axis=0)\n",
    "    top_anchors = np.where(iou_list == best_ious)[0]\n",
    "\n",
    "    # Label the anchors as positive, negative, or neutral\n",
    "    label_column = np.zeros(df_iou.shape[0], dtype=np.int16)\n",
    "    label_column.fill(-1)\n",
    "    label_column[top_anchors] = 1\n",
    "    label_column[np.where(df_iou.max_iou.values >= -0.5)[0]] = 1\n",
    "    label_column[np.where(df_iou.max_iou.values < -0.7)[0]] = 0\n",
    "    df_iou[\"label\"] = label_column\n",
    "\n",
    "    # Calculate the regression targets for the RPN\n",
    "    inside_anchor_width, inside_anchor_height, inside_anchor_center_x, inside_anchor_center_y = to_center_format(\n",
    "        inside_anchor_list[:, 0], \n",
    "        inside_anchor_list[:, 1],\n",
    "        inside_anchor_list[:, 2],\n",
    "        inside_anchor_list[:, 3]\n",
    "    )\n",
    "    \n",
    "    gt_coordinates = np.zeros(np.shape(inside_anchor_list))\n",
    "    for j in range(len(gt_coordinates)):\n",
    "        gt_coordinates[j, :] = bbox_list\n",
    "    \n",
    "    base_width, base_height, base_center_x, base_center_y = to_center_format(\n",
    "        gt_coordinates[:, 0], \n",
    "        gt_coordinates[:, 1],\n",
    "        gt_coordinates[:, 2],\n",
    "        gt_coordinates[:, 3]\n",
    "    )\n",
    "    \n",
    "    # Prevent division by zero\n",
    "    eps = np.finfo(inside_anchor_width.dtype).eps\n",
    "    inside_anchor_height = np.maximum(inside_anchor_height, eps)\n",
    "    inside_anchor_width = np.maximum(inside_anchor_width, eps)\n",
    "    \n",
    "    # Compute the offsets for the RPN regression task\n",
    "    dx = (base_center_x - inside_anchor_center_x) / inside_anchor_width\n",
    "    dy = (base_center_y - inside_anchor_center_y) / inside_anchor_height\n",
    "    dw = np.log(base_width / inside_anchor_width)\n",
    "    dh = np.log(base_height / inside_anchor_height)\n",
    "    \n",
    "    # Add the offsets to the IoU dataframe\n",
    "    df_iou[\"dx\"] = dx\n",
    "    df_iou[\"dy\"] = dy\n",
    "    df_iou[\"dw\"] = dw\n",
    "    df_iou[\"dh\"] = dh\n",
    "\n",
    "    # Create arrays to hold the labels and offsets for all anchors\n",
    "    label_list = np.empty(n_anchors, dtype=np.float32)\n",
    "    label_list.fill(-1)\n",
    "    label_list[df_iou.anchor_id.values] = df_iou.label.values\n",
    "    label_list = np.expand_dims(label_list, 0)\n",
    "    label_list = np.expand_dims(label_list, -1)\n",
    "\n",
    "    offset_list = np.empty(shape=anchor_list.shape, dtype=np.float32)\n",
    "    offset_list.fill(0)\n",
    "    offset_list[df_iou.anchor_id.values] = df_iou[[\"dx\", \"dy\", \"dw\", \"dh\"]].values\n",
    "    offset_list = np.expand_dims(offset_list, 0)\n",
    "\n",
    "    # Combine the offsets and labels into one array\n",
    "    offset_list_label_list = np.column_stack((offset_list[0], label_list[0]))[np.newaxis, :]\n",
    "\n",
    "    # Store the results for this image\n",
    "    offset_list_label_list1[kk, :, :] = offset_list_label_list\n",
    "    label_list1[kk, :, :] = label_list\n",
    "    kk += 1\n",
    "    print(i)\n",
    "\n",
    "# Print the shapes of the resulting arrays\n",
    "print(image_data.shape)\n",
    "print(offset_list_label_list1.shape)\n",
    "print(label_list1.shape)\n",
    "\n",
    "data = {'images': image_data,'reg':offset_list_label_list1,'clc':label_list1,'GT':bbox_list1, 'annotaton':u}\n",
    "\n",
    "with open('./Brainhack/final_project/data_test.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)\n",
    "'''\n",
    "with open('./Brainhack/final_project/data_train.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c9677-5bc0-427a-a12b-d586da30897a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
